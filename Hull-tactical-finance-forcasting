{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88f7de33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-01T12:14:55.959186Z",
     "iopub.status.busy": "2026-01-01T12:14:55.958364Z",
     "iopub.status.idle": "2026-01-01T12:14:58.968619Z",
     "shell.execute_reply": "2026-01-01T12:14:58.967611Z"
    },
    "papermill": {
     "duration": 3.015188,
     "end_time": "2026-01-01T12:14:58.970255",
     "exception": false,
     "start_time": "2026-01-01T12:14:55.955067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found competition API at: /kaggle/input/hull-tactical-market-prediction\n",
      "✅ Successfully imported kaggle_evaluation\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "competition_root = None\n",
    "possible_paths = [\n",
    "    '/kaggle/input/hull-tactical-market-prediction',\n",
    "    '/kaggle/input/hull-tactical', \n",
    "    '/kaggle/input'\n",
    "]\n",
    "\n",
    "for path in possible_paths:\n",
    "    if os.path.exists(path):\n",
    "        # Check if the module folder exists inside\n",
    "        if 'kaggle_evaluation' in os.listdir(path):\n",
    "            competition_root = path\n",
    "            break\n",
    "\n",
    "if competition_root:\n",
    "    print(f\"Found competition API at: {competition_root}\")\n",
    "    \n",
    "    sys.path.append(competition_root)\n",
    "else:\n",
    "    print(\"⚠️ WARNING: Could not find 'kaggle_evaluation' module in standard paths.\")\n",
    "    print(\"Listing /kaggle/input to help debug:\")\n",
    "    for root, dirs, files in os.walk('/kaggle/input'):\n",
    "        print(root, dirs)\n",
    "        break\n",
    "\n",
    "\n",
    "try:\n",
    "    import kaggle_evaluation.default_inference_server\n",
    "    print(\"✅ Successfully imported kaggle_evaluation\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Import failed: {e}\")\n",
    "    # Fallback: Sometimes it's named 'hull_tactical' instead\n",
    "    try:\n",
    "        import hull_tactical\n",
    "        print(\"✅ Successfully imported hull_tactical (Alternate name)\")\n",
    "    except ImportError:\n",
    "        print(\"❌ Both imports failed. Please check the 'Data' tab of the competition.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8e275ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-01T12:14:58.975343Z",
     "iopub.status.busy": "2026-01-01T12:14:58.974930Z",
     "iopub.status.idle": "2026-01-01T12:15:12.391700Z",
     "shell.execute_reply": "2026-01-01T12:15:12.390457Z"
    },
    "papermill": {
     "duration": 13.421038,
     "end_time": "2026-01-01T12:15:12.393327",
     "exception": false,
     "start_time": "2026-01-01T12:14:58.972289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Pruning features to Top 500...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004502 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 21401\n",
      "[LightGBM] [Info] Number of data points in the train set: 7238, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score 0.000017\n",
      "Cleaning and Scaling...\n",
      "Training the Experts...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003952 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21371\n",
      "[LightGBM] [Info] Number of data points in the train set: 7238, number of used features: 94\n",
      "[LightGBM] [Info] Start training from score 0.000017\n",
      "Generating Final Allocation...\n",
      "\n",
      "✅ PRODUCTION READY\n",
      "Final Validation Correlation: 0.0453\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# --- 1. DATA LOADING & SAFE FEATURE SELECTION ---\n",
    "print(\"Loading data...\")\n",
    "df = pd.read_csv('/kaggle/input/hull-tactical-market-prediction/train.csv')\n",
    "\n",
    "# Exclude target and future-info columns\n",
    "target_col = 'market_forward_excess_returns'\n",
    "leak_cols = ['date_id', 'forward_returns', 'risk_free_rate', target_col]\n",
    "all_features = [col for col in df.columns if col not in leak_cols]\n",
    "\n",
    "# Use a Time-Series Split (80% Train / 20% Test)\n",
    "split = int(len(df) * 0.8)\n",
    "X_train_raw, y_train = df[all_features].iloc[:split], df[target_col].iloc[:split]\n",
    "X_test_raw, y_test = df[all_features].iloc[split:], df[target_col].iloc[split:]\n",
    "\n",
    "# --- 2. FEATURE PRUNING (TOP 500) ---\n",
    "# We use 500 features to capture the 0.039 signal while keeping it stable\n",
    "print(\"Pruning features to Top 500...\")\n",
    "lgbm_temp = LGBMRegressor(n_estimators=100, random_state=42)\n",
    "lgbm_temp.fit(X_train_raw.fillna(0), y_train)\n",
    "importances = pd.DataFrame({'f': all_features, 'i': lgbm_temp.feature_importances_})\n",
    "top_500 = importances.sort_values('i', ascending=False)['f'][:500].tolist()\n",
    "\n",
    "# --- 3. PREPROCESSING PIPELINE ---\n",
    "print(\"Cleaning and Scaling...\")\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_c = imputer.fit_transform(X_train_raw[top_500])\n",
    "X_test_c = imputer.transform(X_test_raw[top_500])\n",
    "\n",
    "X_train_s = scaler.fit_transform(X_train_c)\n",
    "X_test_s = scaler.transform(X_test_c)\n",
    "\n",
    "# --- 4. TRAINING THE WINNING ENSEMBLE ---\n",
    "print(\"Training the Experts...\")\n",
    "# Expert 1: LGBM (The Pattern Finder)\n",
    "model_lgbm = LGBMRegressor(n_estimators=1200, learning_rate=0.007, colsample_bytree=0.5, random_state=42)\n",
    "model_lgbm.fit(X_train_c, y_train)\n",
    "\n",
    "# Expert 2: Ridge (The Anchor)\n",
    "model_ridge = Ridge(alpha=300.0)\n",
    "model_ridge.fit(X_train_s, y_train)\n",
    "\n",
    "# --- 5. BLENDING & ALLOCATION ---\n",
    "print(\"Generating Final Allocation...\")\n",
    "p_lgbm = model_lgbm.predict(X_test_c)\n",
    "p_ridge = model_ridge.predict(X_test_s)\n",
    "\n",
    "# Use the 70/30 blend that worked for your 0.039 score\n",
    "blended_preds = (0.5 * p_lgbm) + (0.5 * p_ridge)\n",
    "\n",
    "# Allocation Logic (Threshold + Volatility Scaling + Clipping)\n",
    "market_vol = y_train.std()\n",
    "# Threshold of 0.0004 is your 'Golden' filter\n",
    "final_allocation = np.clip((np.where(np.abs(blended_preds) < 0.0004, 0, blended_preds) / market_vol) * 0.5, 0, 2)\n",
    "\n",
    "# --- 6. FINAL SCORE ---\n",
    "val_corr = np.corrcoef(final_allocation, y_test)[0, 1]\n",
    "print(f\"\\n✅ PRODUCTION READY\")\n",
    "print(f\"Final Validation Correlation: {val_corr:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14861981,
     "sourceId": 111543,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 22.27731,
   "end_time": "2026-01-01T12:15:13.417434",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-01T12:14:51.140124",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
